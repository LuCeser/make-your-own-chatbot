# The Challenge of Chatbot

## 1. 介绍

AlphaGO的成功引爆了人们对于深度学习的关注，好像深度学习成为了人工智能领域的原子弹，无论什么问题只要使用深度学习用上去，什么问题都能统统解决掉。

可惜自然语音处理领域对这颗原子弹不是很感冒，深度学习在NLP的领域的效果大致等于往水面上扔了一块大石块，虽然也能听个响，但相比较于原子弹的威力来说实在不值一提。

当然时间来到2018年，NLP作为人工智能重要的应用领域之一有了非常大的发展，但这些发展都还在我的理解之外，因此对于最新研究成果不会有太多讨论，等到把初级的聊天机器人做出来后，再去根据一些最新的研究成果去迭代我们的Chatbot。

要说Chatbot历史十分悠久，不说那些古早的Chatbot了，2011年iphone 4s发布的同时也向全世界介绍了Siri，到2018年这个时间节点上，Siri的表现依然离我们想象中的智能助手应该有的样子有很大距离，至少Apple自己对Siri也不是很满意，之前还看到Siri要重构的消息… 

虽然我认为Siri作为一款实用软件已经做到这个程度已经很厉害了，而且还能接受调戏，从这个程度上来说不应该对其有太多苛责。不过Siri到现今为止都不能称之为一款多么成功的产品，一定程度上是反映了大众么对对话机器人的期望之高，我们希望它能够了解我们确切的意图，甚至是一些我们自己可能都不明白的想法，而不仅仅是用来调戏。

那么做一个聊天机器人到底难不难呢？

说难也难，说不难也不难。

现在我们对如何做一个聊天机器人一无所知，那么从直觉上来看如果要打造一个聊天机器人，我们第一个想法应该是怎么做呢？

我想大部分人的想法应该跟我差不多，先设定一系列的问答集，然后根据一些规则来匹配问题和回答。

是的，我得说这种做法没有什么问题，至少在人机对话发展的历史上，这种基于规则匹配的方式扮演了很重要的角色。据我自己的工作经历来看，至少在4，5年前，基于规则匹配的方式还是主流。

基于规则匹配的方式自有其优点，从技术手段上实现一个聊天机器人比较简单，其难点在于梳理业务，需要将各种可能性列举出来，当然其劣势也是显而易见的：对于规则之外的问答就显得无能为力了，基本上我们只能把所有规则以外的情况做统一的回复，对不起，我听不懂你的问题。

基于规则匹配的聊天机器人还有另一个问题，它很难做到理解上下文信息，所以其实它对多轮对话是无能为力的。

既然基于规则匹配规则的聊天机器人有那么多问题，我们能否从既往的人类对话中去发掘出规则，或者学习到知识来创建聊天机器人呢？

是的，答案是可以的，而这正是我们要做的事情。在本项目中我们将借助机器学习的力量从我们对话数据中学习，得到一个智能模型，然后通过这个智能模型来实现一个聊天机器人。

## 2. 模型分类

### 2.1 检索模型还是生成模型 

**检索模型（易）**：基于检索模型的聊天机器人其实是从一系列回答集中挑选出符合提问的意图的回答，但是它本身不会产生新的回答。 

**生成模型（难）**：生成式模型看上去更加智能一些，因为生成式模型是根据对话逐字逐字的生成回答，显然生成式模型更难，因为涉及到生产的句子会有语法的问题，我们将不可避免的遇到生成的回答狗屁不通的情况。 

从现阶段来说，并不能简单的判读基于检索的模型更好或者生成式模型更好，对于不同的业务需求，其实这两者各有其使用场景，比如智能客服的场景下，相关的问题都有标准的答案，那么基于检索的模型可能就更适合这种场景。 

### 2.2 长对话还是短对话

**长对话（难）**

**短对话（易）**

这里的长语句指的是聊天机器人需要生成的回答长度，在生成模型下越长的回答就越难。对应于长语句的就是短语句了，它的目标是提出一个简短的问题，给出一个简短的回答。当然在很多业务场景下，我们需要面临的挑战依然是多轮对话，长语句问答。 

### 2.3 开放还是特定领域的对话

**开放领域（难）**：所谓开放意味着我们可以天马行空的与聊天机器人对话，它可以陪你聊天温暖你的心窝，也可以幽默风趣逗你开心，更是一位全知的专家，天上地下无所不包。想想我们的微博，知乎这样的网站就是开放领域的典型场景了。 

**特定领域（易）**：特定领域的聊天机器人就像一个专家，我们的对话会限定在一个特定的集合中。这种特定领域的使用场景很多，比如查询天气，技术支持等。 

## 3. 挑战

### 3.1 上下文

实现一个真正智能的聊天机器人不可避免的会遇到一个关联上下文的问题。

在一个长对话中，人类会持续关注这次对话讲了一些什么，两人之间交换了哪些信息，这就是一个上下文的场景。虽然我们现在拥有一些手段，比如词嵌入(embed)来做一些类似的事情，但是如何理解语言中上下文关系依旧是个很大的挑战。

### 3.2 人格一致性

这在生成模型中是个很大的挑战。在生成模型中，回答是基于我们的问题，但是一些我们看起来一样的问题，得到的答案可能大相径庭。比如，“你几岁了？”，“你的年龄是多少？”在我们的眼里看来这其实是同一个问题，但是对于聊天机器人来说这是一个需要单独研究的领域。可能我们的聊天机器人学会了怎么根据问题来输出回答，但是这些回答并无法保证语义上的一致性。 

### 3.3 模型评估

对于聊天机器人的评估是一件很困难的事，尤其在生成模型中，我们很难利用定性的方法来判断应答是否足够好。它不像机器翻译那样，有一些通用的评测方法，不同的训练数据会造成生成的应答会有多种可能。实际上学界现在的观点是暂时没有一个通用的评测手段去判断一个模型好坏。 

### 3.4 多样性

对于生成模型来说，还有一个共性的问题是，我们使用了一堆数据训练的模型，可能一天到晚只会回答你“嗯”，“好的”。造成这个问题的原因有很多，训练所用的数据，采用的算法等。 

## 4. 小结

总的来说，聊天机器人在人工智能的应用领域也是属于比较难的，上述的问题我们在项目中也将不可避免的遇到



## 参考资料

1. [Deep Learning for Chatbots, Part 1 – Introduction](http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction)
2. [Chatbots with Seq2Seq](http://suriyadeepan.github.io/2016-06-28-easy-seq2seq)